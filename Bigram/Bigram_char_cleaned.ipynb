{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJjsNp3TwTq1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting names and sorting them as numerical values"
      ],
      "metadata": {
        "id": "1uTsY823xwtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt','r').read().splitlines()"
      ],
      "metadata": {
        "id": "2TRhTMPWwfBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words)))) # concatenate all dataset as a sinle string and passes it thru the set constructor\n",
        "# now we need some kind of a lookup table from char to int\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)} # stoi maps a-0, b-1 and so on til z-25\n",
        "# what about ourspecial char\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "n0A_0JbVwlZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the dataset"
      ],
      "metadata": {
        "id": "u5Urnn0iyEPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:]:\n",
        "    chs = ['.'] +  list(w) + ['.']\n",
        "    for ch1 , ch2 in  zip(chs, chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        xs.append(ix1)\n",
        "        ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('# of examples:', num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbZDHCVNwwjf",
        "outputId": "68961452-28d8-4bbd-bbaf-4cb7ef8392c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of examples: 228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(W**2).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZaleKt92-Jc",
        "outputId": "a3628144-e7fd-4616-db04-af6115f0d060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(614.2678, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialization"
      ],
      "metadata": {
        "id": "5EFuH88-xguN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialise 27 random nuerons' weights (each neuron gets 27 inputs)\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = W = torch.randn((27,27), generator = g, requires_grad = True)"
      ],
      "metadata": {
        "id": "7rTnnshcxe-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient descent"
      ],
      "metadata": {
        "id": "qMrOx85QxRfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):  \n",
        "  # Forward Pass\n",
        "  xenc = F.one_hot(xs, num_classes = 27).float() # input to the network: onehot coding\n",
        "  logits = xenc @ W # log counts prediction\n",
        "  counts = logits.exp() # counts, equivalent to N (the nice lil 27X27 matrix above)\n",
        "  probs = counts / counts.sum(1, keepdim = True) # prob for next char\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  # the +0.01 defines the regularization strength ( similar to adding counts (large counts = larger equivalent strength))\n",
        "  print(loss.item())\n",
        "\n",
        "  # Backwards Pass\n",
        "  W.grad = None # set to zeros (like in micro grad) but None is more efficent here than torch.zeros\n",
        "  loss.backward()\n",
        "\n",
        "  # Update\n",
        "  W.data += -50 * W.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ObWxyDIxGqa",
        "outputId": "83bdf319-c673-4372-8eea-f50a568b7a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.696505546569824\n",
            "2.6773719787597656\n",
            "2.6608052253723145\n",
            "2.6463515758514404\n",
            "2.633664846420288\n",
            "2.622471570968628\n",
            "2.6125476360321045\n",
            "2.6037068367004395\n",
            "2.595794916152954\n",
            "2.5886809825897217\n",
            "2.5822560787200928\n",
            "2.5764293670654297\n",
            "2.5711236000061035\n",
            "2.5662729740142822\n",
            "2.5618228912353516\n",
            "2.5577263832092285\n",
            "2.5539441108703613\n",
            "2.550442695617676\n",
            "2.5471925735473633\n",
            "2.5441696643829346\n",
            "2.5413522720336914\n",
            "2.538722038269043\n",
            "2.536262035369873\n",
            "2.5339581966400146\n",
            "2.531797409057617\n",
            "2.529768228530884\n",
            "2.527859926223755\n",
            "2.5260636806488037\n",
            "2.5243701934814453\n",
            "2.522773265838623\n",
            "2.52126407623291\n",
            "2.519836902618408\n",
            "2.5184857845306396\n",
            "2.5172054767608643\n",
            "2.515990734100342\n",
            "2.5148372650146484\n",
            "2.5137407779693604\n",
            "2.512697696685791\n",
            "2.511704921722412\n",
            "2.5107581615448\n",
            "2.509854555130005\n",
            "2.5089924335479736\n",
            "2.5081682205200195\n",
            "2.507380485534668\n",
            "2.5066261291503906\n",
            "2.5059032440185547\n",
            "2.5052106380462646\n",
            "2.5045459270477295\n",
            "2.5039076805114746\n",
            "2.503295421600342\n",
            "2.5027060508728027\n",
            "2.5021393299102783\n",
            "2.5015945434570312\n",
            "2.5010693073272705\n",
            "2.500562906265259\n",
            "2.500075578689575\n",
            "2.4996044635772705\n",
            "2.499150514602661\n",
            "2.4987120628356934\n",
            "2.498288154602051\n",
            "2.4978790283203125\n",
            "2.4974827766418457\n",
            "2.4970996379852295\n",
            "2.4967293739318848\n",
            "2.496370315551758\n",
            "2.4960227012634277\n",
            "2.4956858158111572\n",
            "2.4953596591949463\n",
            "2.4950435161590576\n",
            "2.494736433029175\n",
            "2.4944381713867188\n",
            "2.494149684906006\n",
            "2.4938690662384033\n",
            "2.4935967922210693\n",
            "2.4933323860168457\n",
            "2.493075132369995\n",
            "2.4928252696990967\n",
            "2.492582321166992\n",
            "2.49234676361084\n",
            "2.492116689682007\n",
            "2.4918932914733887\n",
            "2.491676092147827\n",
            "2.491464376449585\n",
            "2.491258382797241\n",
            "2.491058111190796\n",
            "2.4908623695373535\n",
            "2.4906723499298096\n",
            "2.4904870986938477\n",
            "2.4903063774108887\n",
            "2.4901304244995117\n",
            "2.489959478378296\n",
            "2.4897918701171875\n",
            "2.489628314971924\n",
            "2.489469289779663\n",
            "2.489313840866089\n",
            "2.4891626834869385\n",
            "2.4890148639678955\n",
            "2.48887038230896\n",
            "2.48872971534729\n",
            "2.4885923862457275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample from the NN model (finally)"
      ],
      "metadata": {
        "id": "hzJfjiD84zLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(30):\n",
        "  out = []\n",
        "  ix = 0 \n",
        "  while True:\n",
        "    #before\n",
        "    # p = P[ix]\n",
        "#---------------\n",
        "    #NOW\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes = 27).float()\n",
        "    logits = xenc @ W # log counts prediction\n",
        "    counts = logits.exp()\n",
        "    p = counts / counts.sum(1, keepdim = True)\n",
        "#-------------------------------\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator= g).item()\n",
        "    out.append(itos[ix])\n",
        "    #print(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtBEkjmXy-7r",
        "outputId": "259a9eae-db21-4539-ab3b-f6a63c588181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "janasah.\n",
            "p.\n",
            "cfay.\n",
            "a.\n",
            "nn.\n",
            "kohin.\n",
            "tolian.\n",
            "juwe.\n",
            "kalanaauranilevias.\n",
            "dedainrwieta.\n",
            "ssonielylarte.\n",
            "faveumerifontume.\n",
            "phynslenaruani.\n",
            "core.\n",
            "yaenon.\n",
            "ka.\n",
            "jabi.\n",
            "werimikimaynin.\n",
            "anaasn.\n",
            "ssorionszah.\n",
            "dgossmitan.\n",
            "il.\n",
            "le.\n",
            "pann.\n",
            "that.\n",
            "janreli.\n",
            "isa.\n",
            "dyn.\n",
            "rijelujemahaunwyaleva.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q7yyBp2q5kXe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}